identify_product:
  description: |
    Identify which insurance product the user refers to. **Handle typos robustly**.
    If the user's message is exactly one product name or a known alias (case-insensitive) and contains no conflicting references, return that product with confidence 1.0 and do not include a question.
    For non-unique tier names ("Basic", "Silver", "Gold", "Premier", "Platinum"), require additional product cues; otherwise, ask a short clarification question.
    If ambiguous, provide a short clarification question.
    Return a JSON object.
  agent: "product_identifier"
  expected_output: |
    { "product": "Travel" | "Maid" | "Car" | "PersonalAccident" | "", "confidence": 0.0-1.0, "question"?: string }



identify_tiers:
  description: |
    Identify which tiers to compare for a given product from the user's message and recent session context.
    - Inputs (via context): Product, User message, Recent history window (optional)
    - Output 2+ tiers when available for Travel/Maid; for Car, indicate that tiers do not apply.
    - If the message indicates an aggregate request (e.g., "across plans", "all plans", "across all plans", "any plan", "all of them"), return the full set of valid tiers for the product.
    If ambiguous or insufficient, return a short clarification question.
  agent: "tier_identifier"
  expected_output: |
    { "product": "<product>", "tiers": ["<tier>", "<tier>", ...], "question"?: "<short>" }

followup_clarification:
  description: |
    Generate one short, guided clarification question to collect the next missing detail in comparison or summary flow.
    Inputs (via context):
    - await: product|tiers
    - product (may be null)
    - known tiers (optional)
    - recent history (optional)
    - flow_type: comparison|summary (optional, defaults to comparison)
  agent: "followup_clarification_agent"
  expected_output: |
    { "question": "<short question>", "options"?: ["<opt>"] }


synthesize_response:
  description: |
    Use the provided system and user context to synthesize a response.
  agent: "recommendation_responder"
  expected_output: |
    { "response": "<final response>" }

extract_slots:
  description: |
    Extract and update slot values from the user's message using conversation context.
    The context WILL provide a product-specific list of valid slots under "Valid slots" and a JSON object under "Slot meta" describing each slot's type (value|choice|yesno) and any options.
    - Only return keys that appear in the provided "Valid slots" list.
    - Use "Last bot question" to disambiguate yes/no replies.
    - Do NOT validate ranges or reject values based on Slot meta; treat ranges/options as hints only. Always extract the raw value if you can identify it.
    - IMPORTANT: If the user message contains NO slot-related information (e.g., just a product name), return empty strings for all slots and DO NOT set user_needs_explanation.
    - Only set user_needs_explanation if the user EXPLICITLY asks for an explanation about a specific slot (e.g., "what does that mean?", "explain destination").
    - Common phrases that indicate choice preferences:
      * "no budget constraints", "money is no issue", "best coverage" → extract as "comprehensive" for plan_preference
      * "cheapest", "budget option", "basic" → extract as "budget" for plan_preference
    - If a value appears out of range or malformed, still extract it; downstream validation will handle corrections.
    - If the user asks for clarification about a specific slot, set user_needs_explanation to that slot and provide a SHORT explanation (under 50 words) that ends with the right type of request:
      * Yes/No slots → ask a clear (Yes/No) question
      * Choice-based slots → ask the user to choose one of the listed options
      * Value slots → ask for the specific value in the expected format/range (NEVER Yes/No)
  agent: "slot_extractor"
  expected_output: |
    {
      "slot_name_1": "<extracted/updated value or empty string>",
      "slot_name_2": "<extracted/updated value or empty string>",
      "slot_name_3": "<extracted/updated value or empty string>",
      "user_needs_explanation": "<slot_name if user asks for clarification about a slot, otherwise empty string>",
      "explanation": "<short explanation (under 50 words) that ends with a slot-appropriate request if user_needs_explanation is not empty; otherwise empty>"
    }

ask_question:
  description: "Generate a clear, user-friendly question to collect missing slot information for insurance recommendations."
  agent: "question_asker"
  expected_output: |
    { "question": "<clear, concise question for the missing slot>" }


validate_slot:
  description: |
    Your task is to validate and normalize one {product} slot for the given product.

    **CRITICAL RULES:**
    1.  You must validate ONLY the single slot specified in the [Context] block under the "Slot:" key. Do not infer or validate other slots.
    2.  You must use ONLY the validation rules provided in the [Context] block under "Validation rules:".
    3.  Prioritize the provided 'Value' field from the [Context] when it is already in a normalized format (e.g., an integer for days).
    4.  Your response must be a single, complete JSON object that adheres to the Output contract.

    **WHEN INVALID (valid:false):**
    - Always provide both "reason" (brief explanation of what's wrong) and "question" (what to provide instead).
    - Reference the user's input when helpful (e.g., "'Karur' appears to be a city" or "Sep 2020 is in the past").
    - Keep questions short and actionable (<25 words when possible).
    - Pattern: "<Brief reason>. <Clear instruction for what to provide>."
  agent: "slot_validator"
  expected_output: |
    { "valid": true|false, "slot_name": string, "normalized_value"?: string, "question"?: string, "reason"?: string }

 
route_decision:
  description: |
    Decide a single high-level directive for the current turn using a compact JSON context.
    The user content you receive is a JSON object with fields:
      - current_user_message: string
      - session_product: string|null
      - first_turn: boolean
      - history_len: integer
      - has_prior_assistant_question: boolean
      - has_session_pending_flag: boolean (e.g., last_question or a pending info-flow flag)
      - recent_conversation: [ { user?: string, assistant?: string } ] (most recent first, up to 1 pair)
  agent: "orchestrator"
  expected_output: |
    { "directive": "greet" | "handle_recommendation" | "handle_information" | "handle_follow_up" | "plan_only_comparison" | "handle_summary" | "handle_capabilities" | "handle_other" }

construct_follow_up_query:
  description: |
    Build a standalone, precise question/query for retrieval from a follow-up message.
    Inputs (via context):
    - Product
    - Latest user message
    - Recent conversation window (up to 5 turns with user/assistant pairs)
    Goals:
    - Resolve pronouns/deixis ("that", "those", "what about limits?") using the window
    - Avoid adding assumptions; prefer quoting exact entities/benefits from the context when possible
    - Output exactly one concise question that can be answered directly by the knowledge base
  agent: "follow_up_agent"
  expected_output: |
    { "query": "<standalone follow-up query>" }



